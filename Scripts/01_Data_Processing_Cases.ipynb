{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Description: Data Cleaning and Preprocessing Script | Cases \n",
    "\n",
    "## Purpose\n",
    "This script is designed to perform initial data cleaning and preprocessing steps on the raw violence data for the project on Selective and Indiscriminate Violence (VS/VI) in Colombia. Its main goal is to prepare the data for subsequent analysis, metric calculation (Escalation, Intensity), and potential modeling.\n",
    "\n",
    "## Workflow Stage\n",
    "This script is in the Data Cleaning / Preprocessing stage. It takes the raw data, likely loaded from the combined DataFrame generated in the previous step, and transforms it into a clean, structured format suitable for further use in the analytical pipeline.\n",
    "\n",
    "## About\n",
    "This script will handle common data issues such as missing values, incorrect data types, and inconsistencies. It will standardize column names if necessary and potentially aggregate data by relevant temporal (e.g., month) and geographical (Country, Department, or Region) units, depending on the specific analysis level being targeted. The output will be a cleaned dataset ready for calculating metrics and generating features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28997,
     "status": "ok",
     "timestamp": 1710506940684,
     "user": {
      "displayName": "Diego Alejandro Hernandez Castaneda",
      "userId": "18178177893889256336"
     },
     "user_tz": 300
    },
    "id": "qlMJpX1O7Q4i",
    "outputId": "74f5e05b-3505-4acf-bce4-af6b033190f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import product "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "143-Rb3oFRZH"
   },
   "source": [
    "### 1. Initial Setup, Library Imports, and Path Configuration\n",
    "This block performs the initial setup, including importing necessary libraries (pandas, os), defining the path to the raw data folder (one level up in 'Data/raw'), and listing the specific filenames expected for VI and VS violence types. It also defines the list of columns to be extracted from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1697034482233,
     "user": {
      "displayName": "Cristian Alejandro Pulido Quintero",
      "userId": "14005360977426477184"
     },
     "user_tz": 300
    },
    "id": "zON1kAuX7aBm",
    "outputId": "96c91f96-855a-46c6-c1d4-e436bba80365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Desaparicion_Forzada _202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Reclutamiento_ninas_ninos_U_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Acciones_Belicas_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_MInas_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Ataques_a_Poblaciones_202503.xlsx\n",
      "Processing file: Casos_Violencia_Sexual_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Asesinatos_Selectivo_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Atentados_Terroristas_202503.xlsx\n",
      "Processing file: Caso_ Danos_a_Bienes_Civiles_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Secuestro_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Casos_Masacre_202503.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegohernandez/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the folder containing the Excel files.\n",
    "# Assumes the notebook is in a subfolder and the data is one level up.\n",
    "# Adjust '../' if your folder structure is different.\n",
    "data_folder_path = os.path.join(os.getcwd(), '..', 'Data', 'raw','cases') # Example path based on the proposed structure\n",
    "\n",
    "# Define the list of columns to select from each Excel file.\n",
    "columns_to_select = [\n",
    "    \"Año\",\n",
    "    \"Mes\",\n",
    "    \"Día\",\n",
    "    \"ID Caso\",\n",
    "    \"Municipio\",\n",
    "    \"Departamento\",\n",
    "    \"Región\"\n",
    "]\n",
    "\n",
    "# Define the lists of filenames corresponding to each violence type (VI and VS).\n",
    "# These filenames are used to classify the data.\n",
    "vi_files = [\n",
    "    \"Casos_Acciones_Belicas_202503.xlsx\",\n",
    "    \"Casos_Ataques_a_Poblaciones_202503.xlsx\",\n",
    "    \"Casos_Atentados_Terroristas_202503.xlsx\",\n",
    "    \"Casos_MInas_202503.xlsx\",\n",
    "    \"Casos_Reclutamiento_ninas_ninos_U_202503.xlsx\"\n",
    "]\n",
    "\n",
    "vs_files = [\n",
    "    \"Caso_ Danos_a_Bienes_Civiles_202503.xlsx\", # Note: Check for potential extra space in filename \"Caso_ Danos...\"\n",
    "    \"Casos_Asesinatos_Selectivo_202503.xlsx\",\n",
    "    \"Casos_Desaparicion_Forzada _202503.xlsx\", # Note: Check for potential extra space in filename \"Desaparicion_Forzada _\"\n",
    "    \"Casos_Masacre_202503.xlsx\",\n",
    "    \"Casos_Secuestro_202503.xlsx\",\n",
    "    \"Casos_Violencia_Sexual_202503.xlsx\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store the processed dataframes from each file.\n",
    "all_dataframes = []\n",
    "\n",
    "# Iterate through all files in the specified data folder.\n",
    "for filename in os.listdir(data_folder_path):\n",
    "    # Construct the full file path.\n",
    "    file_path = os.path.join(data_folder_path, filename)\n",
    "\n",
    "    # Check if the current item is a file and if it's an Excel file.\n",
    "    if os.path.isfile(file_path) and filename.endswith('.xlsx'):\n",
    "        print(f\"Processing file: {filename}\") # Print the filename being processed\n",
    "\n",
    "        try:\n",
    "            # Read the Excel file into a pandas DataFrame.\n",
    "            df = pd.read_excel(file_path)\n",
    "\n",
    "            # Select only the required columns.\n",
    "            # Use .copy() to avoid SettingWithCopyWarning later.\n",
    "            df_selected = df[columns_to_select].copy()\n",
    "\n",
    "            # Determine the violence type based on the filename and add the 'violence type' column.\n",
    "            if filename in vi_files:\n",
    "                df_selected['violence type'] = 'VI'\n",
    "            elif filename in vs_files:\n",
    "                df_selected['violence type'] = 'VS'\n",
    "            else:\n",
    "                # If the file is not in either list, you might want to skip it\n",
    "                # or assign a different type, depending on your needs.\n",
    "                print(f\"Warning: File '{filename}' not classified as VI or VS. Skipping.\")\n",
    "                continue # Skip this file\n",
    "\n",
    "            # Append the processed DataFrame to the list.\n",
    "            all_dataframes.append(df_selected)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print an error message if reading or processing a file fails.\n",
    "            print(f\"Error processing file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Concatenate DataFrames and Display Summary\n",
    "This block consolidates all individual DataFrames processed from the Excel files into a single combined_df. It includes a check to ensure data was processed before concatenation. Finally, it displays the head, info, and violence type counts of the combined DataFrame for initial verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined DataFrame Head:\n",
      "    Año  Mes  Día  ID Caso  Municipio  Departamento  \\\n",
      "0  1991    5   25   100265  JERUSALEN  CUNDINAMARCA   \n",
      "1  2004   12    2   100282    LA MESA  CUNDINAMARCA   \n",
      "2  1993    3    9   101616     YACOPI  CUNDINAMARCA   \n",
      "3  1997    6    8   102204     BOJAYA         CHOCO   \n",
      "4  2000    6   12   102489      LLORO         CHOCO   \n",
      "\n",
      "                         Región violence type  \n",
      "0  SUROCCIDENTE DE CUNDINAMARCA            VS  \n",
      "1  SUROCCIDENTE DE CUNDINAMARCA            VS  \n",
      "2               MAGDALENA MEDIO            VS  \n",
      "3                        ATRATO            VS  \n",
      "4                        ATRATO            VS  \n",
      "\n",
      "Combined DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 368370 entries, 0 to 368369\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Año            368370 non-null  int64 \n",
      " 1   Mes            368370 non-null  int64 \n",
      " 2   Día            368370 non-null  int64 \n",
      " 3   ID Caso        368370 non-null  int64 \n",
      " 4   Municipio      368370 non-null  object\n",
      " 5   Departamento   368370 non-null  object\n",
      " 6   Región         366197 non-null  object\n",
      " 7   violence type  368370 non-null  object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 22.5+ MB\n",
      "\n",
      "Violence Type Counts:\n",
      "violence type\n",
      "VS    301169\n",
      "VI     67201\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all dataframes in the list into a single DataFrame.\n",
    "# ignore_index=True resets the index of the resulting dataframe.\n",
    "if all_dataframes:\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    # Display the first few rows of the combined DataFrame.\n",
    "    print(\"\\nCombined DataFrame Head:\")\n",
    "    print(combined_df.head())\n",
    "\n",
    "    # Display information about the combined DataFrame (column types, non-null counts).\n",
    "    print(\"\\nCombined DataFrame Info:\")\n",
    "    combined_df.info()\n",
    "\n",
    "    # Optional: Display value counts for the 'violence type' column to verify classification.\n",
    "    print(\"\\nViolence Type Counts:\")\n",
    "    print(combined_df['violence type'].value_counts())\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo Excel files were processed or found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Día</th>\n",
       "      <th>ID Caso</th>\n",
       "      <th>Municipio</th>\n",
       "      <th>Departamento</th>\n",
       "      <th>Región</th>\n",
       "      <th>violence type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>100265</td>\n",
       "      <td>JERUSALEN</td>\n",
       "      <td>CUNDINAMARCA</td>\n",
       "      <td>SUROCCIDENTE DE CUNDINAMARCA</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>100282</td>\n",
       "      <td>LA MESA</td>\n",
       "      <td>CUNDINAMARCA</td>\n",
       "      <td>SUROCCIDENTE DE CUNDINAMARCA</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>101616</td>\n",
       "      <td>YACOPI</td>\n",
       "      <td>CUNDINAMARCA</td>\n",
       "      <td>MAGDALENA MEDIO</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>102204</td>\n",
       "      <td>BOJAYA</td>\n",
       "      <td>CHOCO</td>\n",
       "      <td>ATRATO</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>102489</td>\n",
       "      <td>LLORO</td>\n",
       "      <td>CHOCO</td>\n",
       "      <td>ATRATO</td>\n",
       "      <td>VS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Año  Mes  Día  ID Caso  Municipio  Departamento  \\\n",
       "0  1991    5   25   100265  JERUSALEN  CUNDINAMARCA   \n",
       "1  2004   12    2   100282    LA MESA  CUNDINAMARCA   \n",
       "2  1993    3    9   101616     YACOPI  CUNDINAMARCA   \n",
       "3  1997    6    8   102204     BOJAYA         CHOCO   \n",
       "4  2000    6   12   102489      LLORO         CHOCO   \n",
       "\n",
       "                         Región violence type  \n",
       "0  SUROCCIDENTE DE CUNDINAMARCA            VS  \n",
       "1  SUROCCIDENTE DE CUNDINAMARCA            VS  \n",
       "2               MAGDALENA MEDIO            VS  \n",
       "3                        ATRATO            VS  \n",
       "4                        ATRATO            VS  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.to_csv('../Data/processed/cases/real_total_cases.tsv',sep='\\t')\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Group Cases Data by Year, Month, and Violence Type (1958-2022)\n",
    "This block filters the combined_df for the years 1958-2022 and groups it by year, month, and 'violence type' to count the total number of cases for each type (VI and VS). It ensures all possible Year-Month-Violence Type combinations within this range are present by filling missing entries with a count of 0, creating a complete monthly time series for cases per violence type at the country level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Grouping Cases data by Year, Month, and Violence Type for Country (1958-2022) ---\n",
      "Filtered cases data for years 1958-2022. Shape: (345266, 8)\n",
      "\n",
      "Cases by Month, Year, and Violence Type (Country Level - partial view):\n",
      "Año   Mes  violence type\n",
      "1958  0    VI                3\n",
      "           VS               25\n",
      "      1    VI               10\n",
      "           VS               91\n",
      "      2    VI               13\n",
      "dtype: int64\n",
      "...\n",
      "Año   Mes  violence type\n",
      "2022  10   VS               68\n",
      "      11   VI               22\n",
      "           VS               62\n",
      "      12   VI               30\n",
      "           VS               41\n",
      "dtype: int64\n",
      "\n",
      "Grouped Cases DataFrame (Country Level - with imputed months and types):\n",
      "    Año  Mes violence type  CaseCount\n",
      "0  1958    1            VI         10\n",
      "1  1958    1            VI         10\n",
      "2  1958    1            VI         10\n",
      "3  1958    1            VI         10\n",
      "4  1958    1            VI         10\n",
      "...\n",
      "          Año  Mes violence type  CaseCount\n",
      "1216795  2022   12            VS         41\n",
      "1216796  2022   12            VS         41\n",
      "1216797  2022   12            VS         41\n",
      "1216798  2022   12            VS         41\n",
      "1216799  2022   12            VS         41\n",
      "\n",
      "Info of Grouped Cases DataFrame (Country Level):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1216800 entries, 0 to 1216799\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   Año            1216800 non-null  int64 \n",
      " 1   Mes            1216800 non-null  int64 \n",
      " 2   violence type  1216800 non-null  object\n",
      " 3   CaseCount      1216800 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 37.1+ MB\n",
      "\n",
      "Cases data grouping and imputation for Country level complete.\n",
      "Resulting DataFrame stored in 'grouped_cases_country_monthly_type'.\n"
     ]
    }
   ],
   "source": [
    "# Ensure combined_df exists from the previous step\n",
    "if 'combined_df' not in locals():\n",
    "    print(\"Error: 'combined_df' not found. Please run the previous code block to create it.\")\n",
    "    combined_df = pd.read_csv('../Data/processed/cases/real_total_cases.tsv')\n",
    "else:\n",
    "    # --- 3. Group Cases Data by Year, Month, and Violence Type (1958-2022) for Country Level ---\n",
    "\n",
    "    print(\"\\n--- Grouping Cases data by Year, Month, and Violence Type for Country (1958-2022) ---\")\n",
    "\n",
    "    # 1. Select only records from the years 1958 to 2022.\n",
    "    # Ensure 'Año' column is numeric, handling potential errors.\n",
    "    try:\n",
    "        # Make a copy to avoid modifying the original combined_df directly\n",
    "        df_filtered_years_cases = combined_df.copy()\n",
    "        df_filtered_years_cases['Año'] = pd.to_numeric(df_filtered_years_cases['Año'], errors='coerce')\n",
    "        # Drop rows where 'Año' could not be converted to a number (NaN)\n",
    "        df_filtered_years_cases = df_filtered_years_cases.dropna(subset=['Año']).copy()\n",
    "\n",
    "        # Filter by the specified year range\n",
    "        df_filtered_years_cases = df_filtered_years_cases[\n",
    "            (df_filtered_years_cases['Año'] >= 1958) & (df_filtered_years_cases['Año'] <= 2022)\n",
    "        ].copy()\n",
    "\n",
    "        print(f\"Filtered cases data for years 1958-2022. Shape: {df_filtered_years_cases.shape}\")\n",
    "\n",
    "        # Ensure 'Mes' column is numeric, handling potential errors.\n",
    "        df_filtered_years_cases['Mes'] = pd.to_numeric(df_filtered_years_cases['Mes'], errors='coerce')\n",
    "        # Drop rows where 'Mes' could not be converted to a number (NaN)\n",
    "        df_filtered_years_cases = df_filtered_years_cases.dropna(subset=['Mes']).copy()\n",
    "\n",
    "        # Ensure 'violence type' column exists and is not empty\n",
    "        if 'violence type' not in df_filtered_years_cases.columns or df_filtered_years_cases['violence type'].isnull().all():\n",
    "             print(\"Error: 'violence type' column is missing or empty. Please check the previous data loading step.\")\n",
    "        else:\n",
    "            # 2. Generate a group by for each month within each year and violence type to count the number of cases (rows).\n",
    "            # Group by 'Año', 'Mes', and 'violence type' and count the occurrences (size of each group).\n",
    "            # The result is a pandas Series with multi-index (Año, Mes, violence type).\n",
    "            cases_by_month_year_type_country = df_filtered_years_cases.groupby(['Año', 'Mes', 'violence type']).size()\n",
    "\n",
    "            print(\"\\nCases by Month, Year, and Violence Type (Country Level - partial view):\")\n",
    "            print(cases_by_month_year_type_country.head())\n",
    "            print(\"...\")\n",
    "            print(cases_by_month_year_type_country.tail())\n",
    "\n",
    "\n",
    "            # 3. Ensure each year from 1958 to 2022 has all 12 months for each violence type.\n",
    "            # Create a complete list of all expected Year-Month-Violence Type combinations.\n",
    "            # Get all unique violence types present in the data\n",
    "            unique_violence_types = df_filtered_years_cases['violence type'].unique()\n",
    "\n",
    "            # Create a complete list of all expected Year-Month combinations.\n",
    "            full_date_range_cases = pd.date_range(start='1958-01-01', end='2022-12-01', freq='MS') # Month Start frequency\n",
    "\n",
    "            # Create a list of all possible (Year, Month, Violence Type) combinations\n",
    "            all_combinations = list(product(full_date_range_cases.year, full_date_range_cases.month, unique_violence_types))\n",
    "\n",
    "            # Create a MultiIndex from all combinations\n",
    "            full_year_month_type_index_cases = pd.MultiIndex.from_tuples(\n",
    "                all_combinations,\n",
    "                names=['Año', 'Mes', 'violence type']\n",
    "            )\n",
    "\n",
    "            # Reindex the cases_by_month_year_type_country Series using the complete index.\n",
    "            # This will add missing Year-Month-Violence Type combinations with NaN values.\n",
    "            cases_by_month_year_complete_country = cases_by_month_year_type_country.reindex(full_year_month_type_index_cases)\n",
    "\n",
    "            # Fill the NaN values (for months/types with no cases) with 0.\n",
    "            cases_by_month_year_complete_country = cases_by_month_year_complete_country.fillna(0).astype(int)\n",
    "\n",
    "            # Convert the Series back to a DataFrame for easier handling.\n",
    "            # The column name will be 'CaseCount'.\n",
    "            grouped_cases_country_monthly_type = cases_by_month_year_complete_country.reset_index(name='CaseCount')\n",
    "\n",
    "            # Sort the DataFrame by Year, Month, and Violence Type to ensure chronological order.\n",
    "            grouped_cases_country_monthly_type = grouped_cases_country_monthly_type.sort_values(by=['Año', 'Mes', 'violence type']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "            print(\"\\nGrouped Cases DataFrame (Country Level - with imputed months and types):\")\n",
    "            print(grouped_cases_country_monthly_type.head())\n",
    "            print(\"...\")\n",
    "            print(grouped_cases_country_monthly_type.tail())\n",
    "\n",
    "            print(\"\\nInfo of Grouped Cases DataFrame (Country Level):\")\n",
    "            grouped_cases_country_monthly_type.info()\n",
    "\n",
    "            print(\"\\nCases data grouping and imputation for Country level complete.\")\n",
    "            print(\"Resulting DataFrame stored in 'grouped_cases_country_monthly_type'.\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Required column not found - {e}. Please check column names in the combined_df.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during grouping: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año</th>\n",
       "      <th>Mes</th>\n",
       "      <th>violence type</th>\n",
       "      <th>CaseCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>VI</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>VI</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>VI</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>VI</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>VI</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Año  Mes violence type  CaseCount\n",
       "0  1958    1            VI         10\n",
       "1  1958    1            VI         10\n",
       "2  1958    1            VI         10\n",
       "3  1958    1            VI         10\n",
       "4  1958    1            VI         10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_cases_country_monthly_type.to_csv('../Data/processed/cases/country/1958_2022_cases_country.tsv',sep='\\t')\n",
    "grouped_cases_country_monthly_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Animated Line Plot of VI vs VS Cases (1958-2022)\n",
    "This block creates an animated line plot visualizing the yearly trend of Selective Violence (VS) and Indiscriminate Violence (VI) cases in Colombia from 1958 to 2022. The animation shows how the cumulative case counts for each violence type evolve over time, providing a dynamic view of their historical trajectories. The output is saved as an MP4 video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Animated Line Plot ---\n",
      "\n",
      "Saving animation to /Users/diegohernandez/Documents/GitHub/VS_VI_Source_Code/Scripts/../Images/VI_VS_Colombia.mp4...\n",
      "Animation saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import seaborn as sns # Import seaborn for aesthetics\n",
    "from itertools import product # Import product for generating combinations (if needed for re-running previous cells)\n",
    "import numpy as np # Import numpy for numerical operations, specifically arange\n",
    "\n",
    "grouped_cases_country_monthly_type = pd.read_csv('../Data/processed/cases/country/1958_2022_cases_country.tsv',sep='\\t')\n",
    "\n",
    "# Ensure the grouped_cases_country_monthly_type DataFrame exists\n",
    "if 'grouped_cases_country_monthly_type' not in locals():\n",
    "    print(\"Error: 'grouped_cases_country_monthly_type' not found. Please run the previous code block to create it.\")\n",
    "else:\n",
    "    # --- 4. Generate Animated Line Plot of VI vs VS Cases (1958-2022) ---\n",
    "\n",
    "    print(\"\\n--- Generating Animated Line Plot ---\")\n",
    "\n",
    "    # Prepare data: Group by Year and Violence Type and sum the monthly counts\n",
    "    # This gives the total cases per year for each violence type\n",
    "    yearly_cases_by_type = grouped_cases_country_monthly_type.groupby(['Año', 'violence type'])['CaseCount'].sum().reset_index()\n",
    "\n",
    "    # Pivot the data for easier plotting\n",
    "    # Years will be the index, violence types will be columns, and values will be CaseCount\n",
    "    yearly_cases_pivot = yearly_cases_by_type.pivot(index='Año', columns='violence type', values='CaseCount').fillna(0)\n",
    "\n",
    "    # Ensure both 'VI' and 'VS' columns exist, even if one had 0 cases for all years\n",
    "    for v_type in ['VI', 'VS']:\n",
    "        if v_type not in yearly_cases_pivot.columns:\n",
    "            yearly_cases_pivot[v_type] = 0\n",
    "\n",
    "    # Sort the pivot table by year\n",
    "    yearly_cases_pivot = yearly_cases_pivot.sort_index()\n",
    "\n",
    "    # Calculate cumulative sum for the animation\n",
    "    # This shows the total cases up to a given year\n",
    "    yearly_cases_cumulative = yearly_cases_pivot.cumsum()\n",
    "\n",
    "    # Set up the figure and axes for the plot\n",
    "    plt.style.use('seaborn-v0_8-darkgrid') # Use a nice seaborn style\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    # Set initial plot limits (adjust as needed)\n",
    "    ax.set_xlim(yearly_cases_cumulative.index.min(), yearly_cases_cumulative.index.max())\n",
    "    ax.set_ylim(0, yearly_cases_cumulative.values.max() * 1.1) # Add 10% padding to y-axis\n",
    "\n",
    "    # Set titles and labels\n",
    "    ax.set_title('Cumulative Cases of Selective (VS) and Indiscriminate (VI) Violence in Colombia (1958-2022)', fontsize=14)\n",
    "    ax.set_xlabel('Year', fontsize=12)\n",
    "    ax.set_ylabel('Cumulative Number of Cases', fontsize=12)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- X-axis Tick Adjustment ---\n",
    "    # Determine the range of years\n",
    "    min_year = yearly_cases_cumulative.index.min()\n",
    "    max_year = yearly_cases_cumulative.index.max()\n",
    "\n",
    "    # Set ticks at intervals (e.g., every 10 years)\n",
    "    # Use numpy.arange for consistent spacing\n",
    "    tick_years = np.arange(min_year, max_year + 1, 10) # Adjust the step (10) as needed\n",
    "\n",
    "    # Ensure the last year is included if it's not exactly on an interval\n",
    "    if max_year not in tick_years:\n",
    "         tick_years = np.append(tick_years, max_year)\n",
    "\n",
    "    ax.set_xticks(tick_years)\n",
    "    ax.tick_params(axis='x', rotation=45) # Rotate labels slightly if needed for clarity\n",
    "\n",
    "    # Initialize the lines for the plot\n",
    "    line_vi, = ax.plot([], [], label='VI Cases', color='red', linewidth=2)\n",
    "    line_vs, = ax.plot([], [], label='VS Cases', color='blue', linewidth=2)\n",
    "    # --- ADJUSTMENT HERE: Change loc to 'lower right' ---\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "    # Add a text annotation for the current year (will be updated in animation)\n",
    "    year_text = ax.text(0.02, 0.95, '', transform=ax.transAxes, fontsize=15, color='gray')\n",
    "\n",
    "    # Define the animation update function\n",
    "    def update(frame):\n",
    "        \"\"\"\n",
    "        Updates the plot data for each frame of the animation.\n",
    "        frame: The current frame number (index of the year).\n",
    "        \"\"\"\n",
    "        current_year_index = frame\n",
    "        current_year = yearly_cases_cumulative.index[current_year_index]\n",
    "\n",
    "        # Update data for VI line up to the current year\n",
    "        line_vi.set_data(yearly_cases_cumulative.index[:current_year_index+1],\n",
    "                         yearly_cases_cumulative['VI'].iloc[:current_year_index+1])\n",
    "\n",
    "        # Update data for VS line up to the current year\n",
    "        line_vs.set_data(yearly_cases_cumulative.index[:current_year_index+1],\n",
    "                         yearly_cases_cumulative['VS'].iloc[:current_year_index+1])\n",
    "\n",
    "        # Update the year text annotation\n",
    "        year_text.set_text(f'Year: {current_year}')\n",
    "\n",
    "        # Need to return all artists that were modified\n",
    "        return line_vi, line_vs, year_text, ax.legend_\n",
    "\n",
    "    # Create the animation\n",
    "    # frames: number of frames (equal to the number of years)\n",
    "    # interval: delay between frames in milliseconds\n",
    "    # blit: True means only re-draw the parts that have changed (can be faster)\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(yearly_cases_cumulative.index),\n",
    "                                  interval=200, blit=True) # Adjust interval for speed\n",
    "\n",
    "    # Define the output path for the video\n",
    "    output_dir = os.path.join(os.getcwd(), '..', 'Images')\n",
    "    output_filename = 'VI_VS_Colombia_Cases.mp4'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the animation\n",
    "    # Requires ffmpeg. If you don't have it, you might need to install it\n",
    "    # (e.g., using conda install -c conda-forge ffmpeg or through a system package manager)\n",
    "    try:\n",
    "        print(f\"\\nSaving animation to {output_path}...\")\n",
    "        # Fix for Matplotlib Deprecation Warning: close figure before switching backend\n",
    "        plt.close(fig) # Close the figure before switching\n",
    "        plt.switch_backend('agg') # Switch backend for saving\n",
    "\n",
    "        # Re-create the writer after closing and switching\n",
    "        writer = animation.FFMpegWriter(fps=10) # frames per second\n",
    "        # Re-create the animation object, or ensure the writer can handle the original fig\n",
    "        # It's often better to just pass the fig directly to save if possible,\n",
    "        # or ensure the backend is set correctly BEFORE figure creation if saving without displaying.\n",
    "        # However, since the figure is needed for FuncAnimation, closing *before* saving\n",
    "        # is the fix for the specific warning. Let's try saving the *original* animation object.\n",
    "        ani.save(output_path, writer=writer)\n",
    "\n",
    "        print(\"Animation saved successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving animation: {e}\")\n",
    "        print(\"Please ensure you have ffmpeg installed and accessible in your environment.\")\n",
    "        print(\"You might need to install it using: conda install -c conda-forge ffmpeg\")\n",
    "        print(\"Or using your system's package manager (e.g., sudo apt-get install ffmpeg on Ubuntu or brew install ffmpeg on macOS).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Group Cases Data by Department and Month (1958-2022)\n",
    "This block processes the combined_df to filter and group cases data for each individual department in Colombia. For each department, it calculates the monthly case count from 1958 to 2022, ensuring all months are represented by imputing missing counts with 0. The resulting time series DataFrame for each department is then saved as a separate TSV file in a designated output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Grouping Cases data by Department and Month (1958-2022) ---\n",
      "Ensured output directory exists: /Users/diegohernandez/Documents/GitHub/VS_VI_Source_Code/Scripts/../Data/processed/cases/departments\n",
      "Filtered combined data for years 1958-2022. Shape: (345266, 9)\n",
      "\n",
      "Found 35 unique departments. Processing each...\n",
      "\n",
      "Processing department: CUNDINAMARCA\n",
      "Saved data for CUNDINAMARCA to cundinamarca.tsv\n",
      "\n",
      "Processing department: CHOCO\n",
      "Saved data for CHOCO to choco.tsv\n",
      "\n",
      "Processing department: HUILA\n",
      "Saved data for HUILA to huila.tsv\n",
      "\n",
      "Processing department: LA GUAJIRA\n",
      "Saved data for LA GUAJIRA to laguajira.tsv\n",
      "\n",
      "Processing department: MAGDALENA\n",
      "Saved data for MAGDALENA to magdalena.tsv\n",
      "\n",
      "Processing department: META\n",
      "Saved data for META to meta.tsv\n",
      "\n",
      "Processing department: NARIÑO\n",
      "Saved data for NARIÑO to nariño.tsv\n",
      "\n",
      "Processing department: NORTE DE SANTANDER\n",
      "Saved data for NORTE DE SANTANDER to nortedesantander.tsv\n",
      "\n",
      "Processing department: SANTANDER\n",
      "Saved data for SANTANDER to santander.tsv\n",
      "\n",
      "Processing department: SUCRE\n",
      "Saved data for SUCRE to sucre.tsv\n",
      "\n",
      "Processing department: TOLIMA\n",
      "Saved data for TOLIMA to tolima.tsv\n",
      "\n",
      "Processing department: VALLE DEL CAUCA\n",
      "Saved data for VALLE DEL CAUCA to valledelcauca.tsv\n",
      "\n",
      "Processing department: ARAUCA\n",
      "Saved data for ARAUCA to arauca.tsv\n",
      "\n",
      "Processing department: CASANARE\n",
      "Saved data for CASANARE to casanare.tsv\n",
      "\n",
      "Processing department: PUTUMAYO\n",
      "Saved data for PUTUMAYO to putumayo.tsv\n",
      "\n",
      "Processing department: ANTIOQUIA\n",
      "Saved data for ANTIOQUIA to antioquia.tsv\n",
      "\n",
      "Processing department: BOLIVAR\n",
      "Saved data for BOLIVAR to bolivar.tsv\n",
      "\n",
      "Processing department: CAQUETA\n",
      "Saved data for CAQUETA to caqueta.tsv\n",
      "\n",
      "Processing department: CAUCA\n",
      "Saved data for CAUCA to cauca.tsv\n",
      "\n",
      "Processing department: CESAR\n",
      "Saved data for CESAR to cesar.tsv\n",
      "\n",
      "Processing department: VICHADA\n",
      "Saved data for VICHADA to vichada.tsv\n",
      "\n",
      "Processing department: CORDOBA\n",
      "Saved data for CORDOBA to cordoba.tsv\n",
      "\n",
      "Processing department: CALDAS\n",
      "Saved data for CALDAS to caldas.tsv\n",
      "\n",
      "Processing department: GUAVIARE\n",
      "Saved data for GUAVIARE to guaviare.tsv\n",
      "\n",
      "Processing department: ATLANTICO\n",
      "Saved data for ATLANTICO to atlantico.tsv\n",
      "\n",
      "Processing department: SIN INFORMACION\n",
      "Saved data for SIN INFORMACION to sininformacion.tsv\n",
      "\n",
      "Processing department: BOGOTA, D. C.\n",
      "Saved data for BOGOTA, D. C. to bogota,d.c..tsv\n",
      "\n",
      "Processing department: QUINDIO\n",
      "Saved data for QUINDIO to quindio.tsv\n",
      "\n",
      "Processing department: RISARALDA\n",
      "Saved data for RISARALDA to risaralda.tsv\n",
      "\n",
      "Processing department: EXTERIOR\n",
      "Saved data for EXTERIOR to exterior.tsv\n",
      "\n",
      "Processing department: BOYACA\n",
      "Saved data for BOYACA to boyaca.tsv\n",
      "\n",
      "Processing department: VAUPES\n",
      "Saved data for VAUPES to vaupes.tsv\n",
      "\n",
      "Processing department: GUAINIA\n",
      "Saved data for GUAINIA to guainia.tsv\n",
      "\n",
      "Processing department: AMAZONAS\n",
      "Saved data for AMAZONAS to amazonas.tsv\n",
      "\n",
      "Processing department: ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA\n",
      "Saved data for ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA to archipielagodesanandres,providenciaysantacatalina.tsv\n",
      "\n",
      "Department-level cases data processing and saving complete.\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.read_csv('../Data/processed/cases/real_total_cases.tsv',sep='\\t')\n",
    "\n",
    "# Ensure combined_df exists from the initial loading step\n",
    "if 'combined_df' not in locals():\n",
    "    print(\"Error: 'combined_df' not found. Please run the initial data loading code block.\")\n",
    "else:\n",
    "    # --- 5. Group Cases Data by Department and Month (1958-2022) ---\n",
    "\n",
    "    print(\"\\n--- Grouping Cases data by Department and Month (1958-2022) ---\")\n",
    "\n",
    "    # Define the output directory for department-level case data\n",
    "    output_dir_departments = os.path.join(os.getcwd(), '..', 'Data', 'processed', 'cases', 'departments')\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir_departments, exist_ok=True)\n",
    "    print(f\"Ensured output directory exists: {output_dir_departments}\")\n",
    "\n",
    "    # Define the year range for filtering and imputation\n",
    "    min_year = 1958\n",
    "    max_year = 2022\n",
    "\n",
    "    # Ensure 'Año' and 'Mes' columns are numeric in combined_df before filtering\n",
    "    try:\n",
    "        combined_df['Año'] = pd.to_numeric(combined_df['Año'], errors='coerce')\n",
    "        combined_df['Mes'] = pd.to_numeric(combined_df['Mes'], errors='coerce')\n",
    "        # Drop rows where 'Año' or 'Mes' could not be converted\n",
    "        df_clean_dates = combined_df.dropna(subset=['Año', 'Mes']).copy()\n",
    "\n",
    "        # Filter the combined data for the specified year range once\n",
    "        df_filtered_years = df_clean_dates[\n",
    "            (df_clean_dates['Año'] >= min_year) & (df_clean_dates['Año'] <= max_year)\n",
    "        ].copy()\n",
    "\n",
    "        print(f\"Filtered combined data for years {min_year}-{max_year}. Shape: {df_filtered_years.shape}\")\n",
    "\n",
    "        # Get the list of unique departments from the filtered data\n",
    "        # Drop any potential NaN in 'Departamento' before getting unique values\n",
    "        unique_departments = df_filtered_years['Departamento'].dropna().unique()\n",
    "\n",
    "        if len(unique_departments) == 0:\n",
    "            print(\"Warning: No valid departments found in the filtered data.\")\n",
    "        else:\n",
    "            print(f\"\\nFound {len(unique_departments)} unique departments. Processing each...\")\n",
    "\n",
    "            # Create a complete list of all expected Year-Month combinations for imputation\n",
    "            full_date_range = pd.date_range(start=f'{min_year}-01-01', end=f'{max_year}-12-01', freq='MS') # Month Start frequency\n",
    "            full_year_month_index_template = pd.MultiIndex.from_arrays(\n",
    "                [full_date_range.year, full_date_range.month],\n",
    "                names=['Año', 'Mes']\n",
    "            )\n",
    "\n",
    "            # Loop through each unique department\n",
    "            for department in unique_departments:\n",
    "                print(f\"\\nProcessing department: {department}\")\n",
    "\n",
    "                # Filter data for the current department\n",
    "                df_department = df_filtered_years[df_filtered_years['Departamento'] == department].copy()\n",
    "\n",
    "                if df_department.empty:\n",
    "                    print(f\"No data for department: {department} in the specified year range. Skipping.\")\n",
    "                    continue # Skip to the next department if no data\n",
    "\n",
    "                # Group by 'Año' and 'Mes' and count the number of cases (rows) for this department\n",
    "                # The result is a pandas Series with multi-index (Año, Mes).\n",
    "                cases_by_month_year_dept = df_department.groupby(['Año', 'Mes']).size()\n",
    "\n",
    "                # Reindex the department's monthly case counts using the complete index template.\n",
    "                # This will add missing Year-Month combinations with NaN values.\n",
    "                cases_by_month_year_complete_dept = cases_by_month_year_dept.reindex(full_year_month_index_template)\n",
    "\n",
    "                # Fill the NaN values (for months with no cases) with 0.\n",
    "                cases_by_month_year_complete_dept = cases_by_month_year_complete_dept.fillna(0).astype(int)\n",
    "\n",
    "                # Convert the Series back to a DataFrame.\n",
    "                # The column name will be 'CaseCount'.\n",
    "                grouped_cases_dept_monthly = cases_by_month_year_complete_dept.reset_index(name='CaseCount')\n",
    "\n",
    "                # Sort the DataFrame by Year and Month to ensure chronological order.\n",
    "                grouped_cases_dept_monthly = grouped_cases_dept_monthly.sort_values(by=['Año', 'Mes']).reset_index(drop=True)\n",
    "\n",
    "                # Generate the filename: department name, lowercase, no spaces, .tsv\n",
    "                # Remove spaces and convert to lowercase\n",
    "                filename_dept = department.replace(\" \", \"\").lower() + \".tsv\"\n",
    "                output_path_dept = os.path.join(output_dir_departments, filename_dept)\n",
    "\n",
    "                # Save the DataFrame to a TSV file\n",
    "                try:\n",
    "                    grouped_cases_dept_monthly.to_csv(output_path_dept, sep='\\t', index=False)\n",
    "                    print(f\"Saved data for {department} to {filename_dept}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving data for {department} to {filename_dept}: {e}\")\n",
    "\n",
    "            print(\"\\nDepartment-level cases data processing and saving complete.\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Required column not found - {e}. Please check column names in the combined_df.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during processing: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Group Cases Data by Region and Month (1958-2022)\n",
    "This block processes the combined_df to filter and group cases data for each individual region in Colombia. For each region, it calculates the monthly case count from 1958 to 2022, ensuring all months are represented by imputing missing counts with 0. The resulting time series DataFrame for each region is then saved as a separate TSV file in a designated output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Grouping Cases data by Region and Month (1958-2022) ---\n",
      "Ensured output directory exists: /Users/diegohernandez/Documents/GitHub/VS_VI_Source_Code/Scripts/../Data/processed/cases/regions\n",
      "Filtered combined data for years 1958-2022. Shape: (345266, 9)\n",
      "\n",
      "Found 78 unique regions. Processing each...\n",
      "\n",
      "Processing region: SUROCCIDENTE DE CUNDINAMARCA\n",
      "Saved data for SUROCCIDENTE DE CUNDINAMARCA to suroccidentedecundinamarca.tsv\n",
      "\n",
      "Processing region: MAGDALENA MEDIO\n",
      "Saved data for MAGDALENA MEDIO to magdalenamedio.tsv\n",
      "\n",
      "Processing region: ATRATO\n",
      "Saved data for ATRATO to atrato.tsv\n",
      "\n",
      "Processing region: URABA\n",
      "Saved data for URABA to uraba.tsv\n",
      "\n",
      "Processing region: SUR DEL HUILA\n",
      "Saved data for SUR DEL HUILA to surdelhuila.tsv\n",
      "\n",
      "Processing region: SIERRA NEVADA DE SANTA MARTA\n",
      "Saved data for SIERRA NEVADA DE SANTA MARTA to sierranevadadesantamarta.tsv\n",
      "\n",
      "Processing region: ALTA GUAJIRA\n",
      "Saved data for ALTA GUAJIRA to altaguajira.tsv\n",
      "\n",
      "Processing region: CIENAGA GRANDE DE SANTA MARTA\n",
      "Saved data for CIENAGA GRANDE DE SANTA MARTA to cienagagrandedesantamarta.tsv\n",
      "\n",
      "Processing region: ARIARI GUAYABERO\n",
      "Saved data for ARIARI GUAYABERO to ariariguayabero.tsv\n",
      "\n",
      "Processing region: ALTILLANURA\n",
      "Saved data for ALTILLANURA to altillanura.tsv\n",
      "\n",
      "Processing region: PIEDEMONTE LLANERO\n",
      "Saved data for PIEDEMONTE LLANERO to piedemontellanero.tsv\n",
      "\n",
      "Processing region: ANDEN PACIFICO SUR\n",
      "Saved data for ANDEN PACIFICO SUR to andenpacificosur.tsv\n",
      "\n",
      "Processing region: PROVINCIA DE RICAURTE\n",
      "Saved data for PROVINCIA DE RICAURTE to provinciadericaurte.tsv\n",
      "\n",
      "Processing region: CATATUMBO\n",
      "Saved data for CATATUMBO to catatumbo.tsv\n",
      "\n",
      "Processing region: PROVINCIA DE SOTO\n",
      "Saved data for PROVINCIA DE SOTO to provinciadesoto.tsv\n",
      "\n",
      "Processing region: PROVINCIA COMUNERA\n",
      "Saved data for PROVINCIA COMUNERA to provinciacomunera.tsv\n",
      "\n",
      "Processing region: MONTES DE MARIA\n",
      "Saved data for MONTES DE MARIA to montesdemaria.tsv\n",
      "\n",
      "Processing region: SUR DEL TOLIMA\n",
      "Saved data for SUR DEL TOLIMA to surdeltolima.tsv\n",
      "\n",
      "Processing region: NORTE DEL TOLIMA\n",
      "Saved data for NORTE DEL TOLIMA to nortedeltolima.tsv\n",
      "\n",
      "Processing region: CENTRO DEL VALLE\n",
      "Saved data for CENTRO DEL VALLE to centrodelvalle.tsv\n",
      "\n",
      "Processing region: SUR DEL VALLE\n",
      "Saved data for SUR DEL VALLE to surdelvalle.tsv\n",
      "\n",
      "Processing region: LLANOS ORIENTALES\n",
      "Saved data for LLANOS ORIENTALES to llanosorientales.tsv\n",
      "\n",
      "Processing region: SARARE\n",
      "Saved data for SARARE to sarare.tsv\n",
      "\n",
      "Processing region: BAJO PUTUMAYO\n",
      "Saved data for BAJO PUTUMAYO to bajoputumayo.tsv\n",
      "\n",
      "Processing region: NORTE DE ANTIOQUIA\n",
      "Saved data for NORTE DE ANTIOQUIA to nortedeantioquia.tsv\n",
      "\n",
      "Processing region: ORIENTE ANTIOQUEÑO\n",
      "Saved data for ORIENTE ANTIOQUEÑO to orienteantioqueño.tsv\n",
      "\n",
      "Processing region: NORDESTE ANTIOQUEÑO\n",
      "Saved data for NORDESTE ANTIOQUEÑO to nordesteantioqueño.tsv\n",
      "\n",
      "Processing region: BAJO CAUCA ANTIOQUEÑO\n",
      "Saved data for BAJO CAUCA ANTIOQUEÑO to bajocaucaantioqueño.tsv\n",
      "\n",
      "Processing region: FLORENCIA Y AREA DE INFLUENCIA\n",
      "Saved data for FLORENCIA Y AREA DE INFLUENCIA to florenciayareadeinfluencia.tsv\n",
      "\n",
      "Processing region: PATIA\n",
      "Saved data for PATIA to patia.tsv\n",
      "\n",
      "Processing region: ALTO SINU Y SAN JORGE\n",
      "Saved data for ALTO SINU Y SAN JORGE to altosinuysanjorge.tsv\n",
      "\n",
      "Processing region: EJE CAFETERO\n",
      "Saved data for EJE CAFETERO to ejecafetero.tsv\n",
      "\n",
      "Processing region: AREA METROPOLITANA DE CUCUTA\n",
      "Saved data for AREA METROPOLITANA DE CUCUTA to areametropolitanadecucuta.tsv\n",
      "\n",
      "Processing region: SUROESTE ANTIOQUEÑO\n",
      "Saved data for SUROESTE ANTIOQUEÑO to suroesteantioqueño.tsv\n",
      "\n",
      "Processing region: VALLE DE ABURRA\n",
      "Saved data for VALLE DE ABURRA to valledeaburra.tsv\n",
      "\n",
      "Processing region: CAGUAN\n",
      "Saved data for CAGUAN to caguan.tsv\n",
      "\n",
      "Processing region: PROVINCIA DE GARCIA ROVIRA\n",
      "Saved data for PROVINCIA DE GARCIA ROVIRA to provinciadegarciarovira.tsv\n",
      "\n",
      "Processing region: NORTE DE ATLANTICO\n",
      "Saved data for NORTE DE ATLANTICO to nortedeatlantico.tsv\n",
      "\n",
      "Processing region: AMAZONIA SUR-ORIENTAL\n",
      "Saved data for AMAZONIA SUR-ORIENTAL to amazoniasur-oriental.tsv\n",
      "\n",
      "Processing region: SIN INFORMACION\n",
      "Saved data for SIN INFORMACION to sininformacion.tsv\n",
      "\n",
      "Processing region: NORTE DEL VALLE\n",
      "Saved data for NORTE DEL VALLE to nortedelvalle.tsv\n",
      "\n",
      "Processing region: VALLE DE SAN JUAN\n",
      "Saved data for VALLE DE SAN JUAN to valledesanjuan.tsv\n",
      "\n",
      "Processing region: NORTE DE CORDOBA\n",
      "Saved data for NORTE DE CORDOBA to nortedecordoba.tsv\n",
      "\n",
      "Processing region: MORROSQUILLO Y SABANAS DE SUCRE\n",
      "Saved data for MORROSQUILLO Y SABANAS DE SUCRE to morrosquilloysabanasdesucre.tsv\n",
      "\n",
      "Processing region: NOROCCIDENTE DE CUNDINAMARCA\n",
      "Saved data for NOROCCIDENTE DE CUNDINAMARCA to noroccidentedecundinamarca.tsv\n",
      "\n",
      "Processing region: SUR DE CESAR\n",
      "Saved data for SUR DE CESAR to surdecesar.tsv\n",
      "\n",
      "Processing region: SERRANIA DEL PERIJA\n",
      "Saved data for SERRANIA DEL PERIJA to serraniadelperija.tsv\n",
      "\n",
      "Processing region: NORTE DEL CAUCA\n",
      "Saved data for NORTE DEL CAUCA to nortedelcauca.tsv\n",
      "\n",
      "Processing region: MACIZO COLOMBIANO\n",
      "Saved data for MACIZO COLOMBIANO to macizocolombiano.tsv\n",
      "\n",
      "Processing region: OCCIDENTE ANTIOQUEÑO\n",
      "Saved data for OCCIDENTE ANTIOQUEÑO to occidenteantioqueño.tsv\n",
      "\n",
      "Processing region: CANAL DEL DIQUE\n",
      "Saved data for CANAL DEL DIQUE to canaldeldique.tsv\n",
      "\n",
      "Processing region: AREA METROPOLITANA DE BOGOTA\n",
      "Saved data for AREA METROPOLITANA DE BOGOTA to areametropolitanadebogota.tsv\n",
      "\n",
      "Processing region: LITORAL PACIFICO\n",
      "Saved data for LITORAL PACIFICO to litoralpacifico.tsv\n",
      "\n",
      "Processing region: SUR DE BOLIVAR\n",
      "Saved data for SUR DE BOLIVAR to surdebolivar.tsv\n",
      "\n",
      "Processing region: LA MOJANA\n",
      "Saved data for LA MOJANA to lamojana.tsv\n",
      "\n",
      "Processing region: ALTIPLANO CUNDIBOYACENSE\n",
      "Saved data for ALTIPLANO CUNDIBOYACENSE to altiplanocundiboyacense.tsv\n",
      "\n",
      "Processing region: NORTE DEL HUILA\n",
      "Saved data for NORTE DEL HUILA to nortedelhuila.tsv\n",
      "\n",
      "Processing region: CENTRO DEL HUILA\n",
      "Saved data for CENTRO DEL HUILA to centrodelhuila.tsv\n",
      "\n",
      "Processing region: SUMAPAZ\n",
      "Saved data for SUMAPAZ to sumapaz.tsv\n",
      "\n",
      "Processing region: CENTRO ORIENTE DE ATLANTICO\n",
      "Saved data for CENTRO ORIENTE DE ATLANTICO to centroorientedeatlantico.tsv\n",
      "\n",
      "Processing region: OCCIDENTE DE ATLANTICO\n",
      "Saved data for OCCIDENTE DE ATLANTICO to occidentedeatlantico.tsv\n",
      "\n",
      "Processing region: CENTRO DE NARIÑO\n",
      "Saved data for CENTRO DE NARIÑO to centrodenariño.tsv\n",
      "\n",
      "Processing region: PROVINCIA DE GUANENTA\n",
      "Saved data for PROVINCIA DE GUANENTA to provinciadeguanenta.tsv\n",
      "\n",
      "Processing region: PROVINCIA DE VELEZ\n",
      "Saved data for PROVINCIA DE VELEZ to provinciadevelez.tsv\n",
      "\n",
      "Processing region: MEDIO PUTUMAYO\n",
      "Saved data for MEDIO PUTUMAYO to medioputumayo.tsv\n",
      "\n",
      "Processing region: SUR DE MAGDALENA\n",
      "Saved data for SUR DE MAGDALENA to surdemagdalena.tsv\n",
      "\n",
      "Processing region: MAGDALENA MEDIO ANTIOQUEÑO\n",
      "Saved data for MAGDALENA MEDIO ANTIOQUEÑO to magdalenamedioantioqueño.tsv\n",
      "\n",
      "Processing region: SURORIENTE DE NORTE DE SANTANDER\n",
      "Saved data for SURORIENTE DE NORTE DE SANTANDER to surorientedenortedesantander.tsv\n",
      "\n",
      "Processing region: SUROCCIDENTE DE NORTE DE SANTANDER\n",
      "Saved data for SUROCCIDENTE DE NORTE DE SANTANDER to suroccidentedenortedesantander.tsv\n",
      "\n",
      "Processing region: SUR DE NARIÑO\n",
      "Saved data for SUR DE NARIÑO to surdenariño.tsv\n",
      "\n",
      "Processing region: CENTRO OCCIDENTE DE NARIÑO\n",
      "Saved data for CENTRO OCCIDENTE DE NARIÑO to centrooccidentedenariño.tsv\n",
      "\n",
      "Processing region: NORTE DE NARIÑO\n",
      "Saved data for NORTE DE NARIÑO to nortedenariño.tsv\n",
      "\n",
      "Processing region: OCCIDENTE DE NARIÑO\n",
      "Saved data for OCCIDENTE DE NARIÑO to occidentedenariño.tsv\n",
      "\n",
      "Processing region: SERRANIA DE LOS YARIGUIES\n",
      "Saved data for SERRANIA DE LOS YARIGUIES to serraniadelosyariguies.tsv\n",
      "\n",
      "Processing region: ALTO PUTUMAYO\n",
      "Saved data for ALTO PUTUMAYO to altoputumayo.tsv\n",
      "\n",
      "Processing region: CENTRO DE NORTE DE SANTANDER\n",
      "Saved data for CENTRO DE NORTE DE SANTANDER to centrodenortedesantander.tsv\n",
      "\n",
      "Processing region: ORIENTE DE BOYACA\n",
      "Saved data for ORIENTE DE BOYACA to orientedeboyaca.tsv\n",
      "\n",
      "Processing region: ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA\n",
      "Saved data for ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA to archipielagodesanandres,providenciaysantacatalina.tsv\n",
      "\n",
      "Region-level cases data processing and saving complete.\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.read_csv('../Data/processed/cases/real_total_cases.tsv',sep='\\t')\n",
    "\n",
    "# Ensure combined_df exists from the initial loading step\n",
    "if 'combined_df' not in locals():\n",
    "    print(\"Error: 'combined_df' not found. Please run the initial data loading code block.\")\n",
    "else:\n",
    "    # --- 6. Group Cases Data by Region and Month (1958-2022) ---\n",
    "\n",
    "    print(\"\\n--- Grouping Cases data by Region and Month (1958-2022) ---\")\n",
    "\n",
    "    # Define the output directory for region-level case data\n",
    "    output_dir_regions = os.path.join(os.getcwd(), '..', 'Data', 'processed', 'cases', 'regions')\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir_regions, exist_ok=True)\n",
    "    print(f\"Ensured output directory exists: {output_dir_regions}\")\n",
    "\n",
    "    # Define the year range for filtering and imputation\n",
    "    min_year = 1958\n",
    "    max_year = 2022\n",
    "\n",
    "    # Ensure 'Año' and 'Mes' columns are numeric in combined_df before filtering\n",
    "    try:\n",
    "        # No need to re-convert if already done in previous steps, but good for robustness\n",
    "        combined_df['Año'] = pd.to_numeric(combined_df['Año'], errors='coerce')\n",
    "        combined_df['Mes'] = pd.to_numeric(combined_df['Mes'], errors='coerce')\n",
    "        # Drop rows where 'Año' or 'Mes' could not be converted\n",
    "        df_clean_dates = combined_df.dropna(subset=['Año', 'Mes']).copy()\n",
    "\n",
    "        # Filter the combined data for the specified year range once\n",
    "        df_filtered_years = df_clean_dates[\n",
    "            (df_clean_dates['Año'] >= min_year) & (df_clean_dates['Año'] <= max_year)\n",
    "        ].copy()\n",
    "\n",
    "        print(f\"Filtered combined data for years {min_year}-{max_year}. Shape: {df_filtered_years.shape}\")\n",
    "\n",
    "        # Get the list of unique regions from the filtered data\n",
    "        # Drop any potential NaN in 'Región' before getting unique values\n",
    "        unique_regions = df_filtered_years['Región'].dropna().unique()\n",
    "\n",
    "        if len(unique_regions) == 0:\n",
    "            print(\"Warning: No valid regions found in the filtered data.\")\n",
    "        else:\n",
    "            print(f\"\\nFound {len(unique_regions)} unique regions. Processing each...\")\n",
    "\n",
    "            # Create a complete list of all expected Year-Month combinations for imputation\n",
    "            full_date_range = pd.date_range(start=f'{min_year}-01-01', end=f'{max_year}-12-01', freq='MS') # Month Start frequency\n",
    "            full_year_month_index_template = pd.MultiIndex.from_arrays(\n",
    "                [full_date_range.year, full_date_range.month],\n",
    "                names=['Año', 'Mes']\n",
    "            )\n",
    "\n",
    "            # Loop through each unique region\n",
    "            for region in unique_regions:\n",
    "                print(f\"\\nProcessing region: {region}\")\n",
    "\n",
    "                # Filter data for the current region\n",
    "                df_region = df_filtered_years[df_filtered_years['Región'] == region].copy()\n",
    "\n",
    "                if df_region.empty:\n",
    "                    print(f\"No data for region: {region} in the specified year range. Skipping.\")\n",
    "                    continue # Skip to the next region if no data\n",
    "\n",
    "                # Group by 'Año' and 'Mes' and count the number of cases (rows) for this region\n",
    "                # The result is a pandas Series with multi-index (Año, Mes).\n",
    "                cases_by_month_year_region = df_region.groupby(['Año', 'Mes']).size()\n",
    "\n",
    "                # Reindex the region's monthly case counts using the complete index template.\n",
    "                # This will add missing Year-Month combinations with NaN values.\n",
    "                cases_by_month_year_complete_region = cases_by_month_year_region.reindex(full_year_month_index_template)\n",
    "\n",
    "                # Fill the NaN values (for months with no cases) with 0.\n",
    "                cases_by_month_year_complete_region = cases_by_month_year_complete_region.fillna(0).astype(int)\n",
    "\n",
    "                # Convert the Series back to a DataFrame.\n",
    "                # The column name will be 'CaseCount'.\n",
    "                grouped_cases_region_monthly = cases_by_month_year_complete_region.reset_index(name='CaseCount')\n",
    "\n",
    "                # Sort the DataFrame by Year and Month to ensure chronological order.\n",
    "                grouped_cases_region_monthly = grouped_cases_region_monthly.sort_values(by=['Año', 'Mes']).reset_index(drop=True)\n",
    "\n",
    "                # Generate the filename: region name, lowercase, no spaces, .tsv\n",
    "                # Remove spaces and convert to lowercase\n",
    "                filename_region = region.replace(\" \", \"\").lower() + \".tsv\"\n",
    "                output_path_region = os.path.join(output_dir_regions, filename_region)\n",
    "\n",
    "                # Save the DataFrame to a TSV file\n",
    "                try:\n",
    "                    grouped_cases_region_monthly.to_csv(output_path_region, sep='\\t', index=False)\n",
    "                    print(f\"Saved data for {region} to {filename_region}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving data for {region} to {filename_region}: {e}\")\n",
    "\n",
    "            print(\"\\nRegion-level cases data processing and saving complete.\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Required column not found - {e}. Please check column names in the combined_df.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python_Colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
